// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package jetstream_proto;

// TODO: Merge this with main JetStream core once we settle on an API.

service Orchestrator {
  // Generate the next model tokens.
  rpc Decode(DecodeRequest) returns (stream DecodeResponse) {}
}
message DecodeRequest {
  // Where to load any pre-existing kv cache from.
  string session_cache = 1;
  // New text from a user or tool.
  string additional_text = 2;
  int32 priority = 3;
  // The maximum output length of a sequence. It's used in JetStream to control
  // the output/decode length of a sequence. It would not be used in the engine.
  // We should always set max_tokens <= (max_target_length -
  // max_prefill_predict_length). max_target_length is the maximum length of a
  // sequence; max_prefill_predict_length is the maximum length of the
  // input/prefill of a sequence.
  int32 max_tokens = 4;
}
message DecodeResponse {
  // List of responses, one per sample. The list size depends on text generation strategy the engine used.
  repeated RepeatedTokenIds response = 1;
}
message RepeatedTokenIds {
  // List of token ids, one list per sample. When speculative decoding is disabled, the list size should be 1; When speculative decoding is enabled, the list size should be >= 1.
  repeated int32 token_ids = 1;
}